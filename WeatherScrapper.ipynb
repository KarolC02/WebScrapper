{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from os import sys\n",
    "from selenium import webdriver\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_code_dic = dict()\n",
    "station_code_dic[\"TaiPei\"] = \"RCSS\"\n",
    "station_code_dic[\"ShenZhen\"] = \"ZGSZ\"\n",
    "station_code_dic[\"Teheran\"] = \"OIII\"\n",
    "station_code_dic[\"HangZhou\"] = \"ZSHC\"\n",
    "station_code_dic[\"BeiJing\"] = \"ZBAA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_temp(city_name : str, _date : date, station_code_dic : dict = station_code_dic) -> int:\n",
    "\n",
    "    code = station_code_dic[city_name]\n",
    "\n",
    "    url = f\"https://www.wunderground.com/history/daily/{code}/date/{_date.year}-{_date.month}-{_date.day}\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"observation-table\")))\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        table = soup.find_all('div', class_='observation-table')\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    vals = []\n",
    "    if table:\n",
    "        rows = table[0].find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 2:\n",
    "                temp = cols[1].find('span', class_=\"wu-value wu-value-to\")\n",
    "                if temp:\n",
    "                    raw = str(temp)\n",
    "                    match = re.search(r'class=\"wu-value wu-value-to\">(\\d+)</span>', raw)\n",
    "                    if match:\n",
    "                        value = int(match.group(1))\n",
    "                        vals.append(value)\n",
    "                        # print(f\"Row {n}: {value}Â°F\")\n",
    "\n",
    "    if not vals:\n",
    "        raise ValueError(f\"No temperature data found for {city_name} on {_date}\")\n",
    "    return max(vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_csv_with_weather_data(station_code_dic : dict = station_code_dic, specific_cities : list[str] = station_code_dic.keys(), limited_days = False, days_to_cover : int = -1) -> None:\n",
    "    for city in specific_cities:\n",
    "        start_date = date(2005,1,1)\n",
    "        end_date = date(2025,4,15)\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        file_name = f\"output/{city}_weather_{start_date}_to_{end_date}.csv\"\n",
    "        \n",
    "        current_date = start_date\n",
    "\n",
    "        with open(file_name, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Date\", \"Max Temperature\"])\n",
    "\n",
    "        nDays = 0\n",
    "        while current_date <= end_date:\n",
    "            nDays += 1\n",
    "            try:\n",
    "                max_temp = get_max_temp(city, current_date)\n",
    "                max_temp = round((max_temp - 32) * 5 / 9, 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error on {city} - {current_date}: {e}\")\n",
    "                max_temp = \"-\"\n",
    "\n",
    "            with open(file_name, 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([current_date, max_temp])\n",
    "            \n",
    "                current_date += timedelta(days=1)\n",
    "            \n",
    "            if limited_days and nDays >= days_to_cover:\n",
    "                print(f\"Breaking scrapping for city {city} after successfully scrapping {nDays} days\")\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking scrapping for city TaiPei after successfully scrapping 5 days\n",
      "The whole process will take approximately 39 hours\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "days = 5\n",
    "fill_csv_with_weather_data(limited_days=True, days_to_cover=days, specific_cities = [\"TaiPei\"])\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "more_iterations = int(365 / days  * 20)\n",
    "estimation_seconds = int(elapsed * more_iterations)\n",
    "estimation_hours = int(estimation_seconds / 3600)\n",
    "\n",
    "print(f\"The whole process will take approximately {estimation_hours} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
